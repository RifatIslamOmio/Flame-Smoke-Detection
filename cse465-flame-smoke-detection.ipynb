{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix,precision_recall_fscore_support\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nfrom torchvision import datasets, transforms,models\nimport pandas as pd\nfrom PIL import Image\nimport itertools\nfrom IPython.display import display\nimport os\nimport time\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npd.set_option('display.max_rows', 301)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-21T19:14:30.162162Z","iopub.execute_input":"2021-09-21T19:14:30.16277Z","iopub.status.idle":"2021-09-21T19:14:32.746842Z","shell.execute_reply.started":"2021-09-21T19:14:30.162733Z","shell.execute_reply":"2021-09-21T19:14:32.745888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(torch.cuda.get_device_name(0))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:14:32.748251Z","iopub.execute_input":"2021-09-21T19:14:32.748558Z","iopub.status.idle":"2021-09-21T19:14:32.753197Z","shell.execute_reply.started":"2021-09-21T19:14:32.748529Z","shell.execute_reply":"2021-09-21T19:14:32.751976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For plotting confusion matrix in kaggle kernel \n#Credit: https://www.kaggle.com/grfiv4/plot-a-confusion-matrix\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n\n\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:14:32.755715Z","iopub.execute_input":"2021-09-21T19:14:32.756266Z","iopub.status.idle":"2021-09-21T19:14:32.77225Z","shell.execute_reply.started":"2021-09-21T19:14:32.756218Z","shell.execute_reply":"2021-09-21T19:14:32.771395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Image Input from Dataset\n### Performing Operations: Dataload,Transform,Split, Compose(Normalize,Resize,Random-Flip,Crop etc.)","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n   transforms.RandomRotation(10),\n   transforms.RandomHorizontalFlip(), #default probabily\n   transforms.Resize(224),\n   transforms.CenterCrop(224),\n   transforms.ToTensor(),\n   transforms.Normalize([0.485,0.456,0.406],\n                        [0.229,0.224,0.225])                            \n])\n\ntest_transform = transforms.Compose([\n   transforms.Resize(224),\n   transforms.CenterCrop(224),\n   transforms.ToTensor(),\n   transforms.Normalize([0.485,0.456,0.406], \n                        [0.229,0.224,0.225])                                 \n])","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:14:32.773995Z","iopub.execute_input":"2021-09-21T19:14:32.774432Z","iopub.status.idle":"2021-09-21T19:14:32.794287Z","shell.execute_reply.started":"2021-09-21T19:14:32.774397Z","shell.execute_reply":"2021-09-21T19:14:32.792678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '../input/fire-smoke-and-neutral/FIRE-SMOKE-DATASET/'\n#Using image folder (0f torchvision)\ntrain_data = datasets.ImageFolder(os.path.join(root,'Train'), transform=train_transform)\ntest_data = datasets.ImageFolder(os.path.join(root,'Test'), transform=test_transform)\n\ntorch.manual_seed(42)\n\n#data loader\ntrain_loader = DataLoader(train_data, batch_size=10, shuffle= True)\ntest_loader = DataLoader(test_data, batch_size=10,shuffle= True)\n\n\nclass_names = train_data.classes\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:14:32.796196Z","iopub.execute_input":"2021-09-21T19:14:32.797012Z","iopub.status.idle":"2021-09-21T19:14:34.324509Z","shell.execute_reply.started":"2021-09-21T19:14:32.796961Z","shell.execute_reply":"2021-09-21T19:14:34.323151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### C.Name   -   Index\n#### Fire    -->   0\n#### Neutral -->   1\n#### Smoke   -->   2","metadata":{}},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:14:34.325929Z","iopub.execute_input":"2021-09-21T19:14:34.326271Z","iopub.status.idle":"2021-09-21T19:14:34.33557Z","shell.execute_reply.started":"2021-09-21T19:14:34.326231Z","shell.execute_reply":"2021-09-21T19:14:34.334477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train data size: {len(train_data)}\")\nprint(f\"Test data size: {len(test_data)}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:14:34.337412Z","iopub.execute_input":"2021-09-21T19:14:34.337751Z","iopub.status.idle":"2021-09-21T19:14:34.350451Z","shell.execute_reply.started":"2021-09-21T19:14:34.33772Z","shell.execute_reply":"2021-09-21T19:14:34.349083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['Fire', 'Neutral', 'Smoke']\ncount = {'Fire':0, 'Neutral':0 , 'Smoke':0}\nfor images, labels in train_loader:\n    for x in labels:\n        count[classes[x.item()]] +=1 \ncount","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:14:40.330491Z","iopub.execute_input":"2021-09-21T19:14:40.330908Z","iopub.status.idle":"2021-09-21T19:15:23.842337Z","shell.execute_reply.started":"2021-09-21T19:14:40.33086Z","shell.execute_reply":"2021-09-21T19:15:23.841541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape \n#output (#images per batch, #channels, dimensions)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-19T09:51:12.410826Z","iopub.execute_input":"2021-09-19T09:51:12.411126Z","iopub.status.idle":"2021-09-19T09:51:12.419141Z","shell.execute_reply.started":"2021-09-19T09:51:12.411098Z","shell.execute_reply":"2021-09-19T09:51:12.418324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For viewing original image on plt.imshow\n#Denormalized\n#to understand how normalization applied\ninverse_normalized = transforms.Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225], \n                                      std=[1/0.229,1/0.224,1/0.225])\n# image_inv = inverse_normalized(NORMALIZED_IMAGE)\n# plt.imshow(np.transpose(im_inv.numpy(), (1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2021-09-19T09:51:12.420672Z","iopub.execute_input":"2021-09-19T09:51:12.421171Z","iopub.status.idle":"2021-09-19T09:51:12.427014Z","shell.execute_reply.started":"2021-09-19T09:51:12.421137Z","shell.execute_reply":"2021-09-19T09:51:12.42614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Label:', labels.numpy())\nprint('Class:', *np.array([class_names[i] for i in labels]))\n\nim = make_grid(images, nrow = 5)\ninv_normalized = transforms.Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225], \n                                      std=[1/0.229,1/0.224,1/0.225])\nim_inv = inv_normalized(im)\n\nplt.figure(figsize=(12,4))\nplt.imshow(np.transpose(im_inv.numpy(), (1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:15:23.843706Z","iopub.execute_input":"2021-09-21T19:15:23.844235Z","iopub.status.idle":"2021-09-21T19:15:24.246203Z","shell.execute_reply.started":"2021-09-21T19:15:23.84418Z","shell.execute_reply":"2021-09-21T19:15:24.244913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # In Channels -> 3 \n        # Out channels -> 6\n        # Filter -> 3x3\n        # Stride -> 1\n        self.conv1 = nn.Conv2d(3,6,3,1)\n\n        # In Channels -> 6 \n        # Out channels -> 16\n        # Filter -> 3x3\n        # Stride -> 1\n        self.conv2 = nn.Conv2d(6,16,3,1)\n        \n        # **Adding another convulotional layer**\n        # In Channels -> 16\n        # Out channels -> 26\n        # Filter -> 3x3\n        # Stride -> 1\n        self.conv3 = nn.Conv2d(16,26,3,1)\n        \n        # **Adding another convulotional layer**\n        # In Channels -> 26\n        # Out channels -> 36\n        # Filter -> 3x3\n        # Stride -> 1\n        self.conv4 = nn.Conv2d(26,36,3,1)\n        \n        \n        # **Adding another convulotional layer**\n        # In Channels -> 36\n        # Out channels -> \n        # Filter -> 3x3\n        # Stride -> 1\n        self.conv5 = nn.Conv2d(36,48,3,1)\n\n        \n    # input calculation -> Floor(((((((((224-2)/2)-2)/2)-2)/2)-2)/2)-2)/2  = 5 \n    #(-2 for each filter with no padding)\n    # (/2 for each pooling)\n        self.fc1 = nn.Linear(5*5*48,512) \n        self.fc2 = nn.Linear(512,256) \n        self.fc3 = nn.Linear(256,80)\n        self.fc4 = nn.Linear(80,3)\n    \n    def forward(self,X):\n        X = F.relu(self.conv1(X))\n        X = F.max_pool2d(X,2,2) #2x2 pooling with stride 2\n\n        X = F.relu(self.conv2(X))\n        X = F.max_pool2d(X,2,2) #2x2 pooling with stride 2\n        \n        X = F.relu(self.conv3(X))\n        X = F.max_pool2d(X,2,2) #2x2 pooling with stride 2\n        \n        X = F.relu(self.conv4(X))\n        X = F.max_pool2d(X,2,2) #2x2 pooling with stride 2\n        \n        X = F.relu(self.conv5(X))\n        X = F.max_pool2d(X,2,2) #2x2 pooling with stride 2\n\n        X = X.view(-1, 5*5*48)\n        \n        X = F.relu(self.fc1(X))\n        X = F.relu(self.fc2(X))\n        X = F.relu(self.fc3(X))\n        X = self.fc4(X)\n\n        return F.log_softmax(X, dim=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:15:24.332138Z","iopub.execute_input":"2021-09-21T19:15:24.332421Z","iopub.status.idle":"2021-09-21T19:15:24.351419Z","shell.execute_reply.started":"2021-09-21T19:15:24.332394Z","shell.execute_reply":"2021-09-21T19:15:24.350145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyper parameters\nSEED = 101\nLEARNING_RATE = 0.001\nEPOCHS = 9-8\nMAX_BATCH_SIZE = 9999999 #unlimited (whole dataset)\n\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\n\n#CNN Model\nmodelCNN = ConvNetwork()\nmodelCNN = modelCNN.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(modelCNN.parameters(), lr= LEARNING_RATE)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:15:24.389263Z","iopub.execute_input":"2021-09-21T19:15:24.389679Z","iopub.status.idle":"2021-09-21T19:15:24.407919Z","shell.execute_reply.started":"2021-09-21T19:15:24.389632Z","shell.execute_reply":"2021-09-21T19:15:24.406663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelCNN","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:15:24.409026Z","iopub.execute_input":"2021-09-21T19:15:24.40947Z","iopub.status.idle":"2021-09-21T19:15:24.416297Z","shell.execute_reply.started":"2021-09-21T19:15:24.409438Z","shell.execute_reply":"2021-09-21T19:15:24.415105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_params = 0\nfor parameters in modelCNN.parameters():\n    total_params += parameters.numel()\nprint(f\"Total params: {total_params} \")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:15:24.417528Z","iopub.execute_input":"2021-09-21T19:15:24.418039Z","iopub.status.idle":"2021-09-21T19:15:24.430819Z","shell.execute_reply.started":"2021-09-21T19:15:24.417991Z","shell.execute_reply":"2021-09-21T19:15:24.429907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getNumParams(model):\n    total_params = 0\n    for parameters in modelCNN.parameters():\n        total_params += parameters.numel()\n    return total_params","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:15:24.432265Z","iopub.execute_input":"2021-09-21T19:15:24.432907Z","iopub.status.idle":"2021-09-21T19:15:24.447118Z","shell.execute_reply.started":"2021-09-21T19:15:24.432858Z","shell.execute_reply":"2021-09-21T19:15:24.446103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"getNumParams(modelCNN)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:15:24.448631Z","iopub.execute_input":"2021-09-21T19:15:24.449321Z","iopub.status.idle":"2021-09-21T19:15:24.466862Z","shell.execute_reply.started":"2021-09-21T19:15:24.449272Z","shell.execute_reply":"2021-09-21T19:15:24.465522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\n#Limiting batch sizes\nmax_trn_batch = MAX_BATCH_SIZE #1800 \nmax_tst_batch = MAX_BATCH_SIZE #300 \n\ntrain_losses = []\ntest_losses = []\ntrain_correct = []\ntest_correct = []\n\n\nfor i in range(EPOCHS):\n    trn_corr = 0\n    tst_corr = 0\n\n    for b, (X_train, y_train) in enumerate(train_loader):\n        #Limiting batch sizes for testing the model (if required)\n        if b==max_trn_batch:\n            break     \n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n\n        b+=1\n        y_pred = modelCNN(X_train)\n        loss = criterion(y_pred, y_train) #Loss calculation\n\n        #Storing correct predictions (training)\n        predicted = torch.max(y_pred.data,1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n\n        #Backprop -> updating parameters\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (b%70 ==0):\n            print(f\"Epoch:{i+1} Batch:{b} Loss:{loss.item():.7f} Training accuracy:{trn_corr.item()*100/(10*b):7.3f}% \")\n      \n    train_losses.append(loss)\n    train_correct.append(trn_corr)\n\n    # For test Set\n    with torch.no_grad():\n        for b,(X_test,y_test) in enumerate(test_loader):\n            \n            if( b==max_tst_batch):\n                break\n            \n            X_test = X_test.to(device)\n            y_test = y_test.to(device)\n            \n            y_test_pred = modelCNN(X_test)\n            predicted = torch.max(y_test_pred.data,1)[1]\n            batch_corr = (predicted == y_test).sum()\n            tst_corr = tst_corr + batch_corr\n\n    loss = criterion(y_test_pred, y_test)\n    test_losses.append(loss)\n    test_correct.append(tst_corr)\n\ntotal_time = time.time() - start_time\nprint(f'Time taken: {(total_time/60):.2f} mins')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-21T19:15:24.47048Z","iopub.execute_input":"2021-09-21T19:15:24.470872Z","iopub.status.idle":"2021-09-21T19:16:15.471592Z","shell.execute_reply.started":"2021-09-21T19:15:24.470825Z","shell.execute_reply":"2021-09-21T19:16:15.470215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nmodel_file = \"custom_cnn.pickle\"\nwith open(model_file,'wb') as f:\n    pickle.dump(modelCNN, f)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:16:41.6113Z","iopub.execute_input":"2021-09-21T19:16:41.611686Z","iopub.status.idle":"2021-09-21T19:16:41.622929Z","shell.execute_reply.started":"2021-09-21T19:16:41.611651Z","shell.execute_reply":"2021-09-21T19:16:41.621753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses, label='training loss')\nplt.plot(test_losses, label='validation loss')\nplt.title('Train-Test Loss')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-09-21T19:16:15.47311Z","iopub.execute_input":"2021-09-21T19:16:15.473519Z","iopub.status.idle":"2021-09-21T19:16:15.680828Z","shell.execute_reply.started":"2021-09-21T19:16:15.473473Z","shell.execute_reply":"2021-09-21T19:16:15.679743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([t/270 for t in train_correct], label='training accuracy')\nplt.plot([t/30 for t in test_correct], label='validation accuracy')\nplt.title('Accuracy at the end of each epoch (CNN)')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_correct)\ntest_data_size = len(test_data)\nprint(f'Test accuracy: {test_correct[-1].item()*100/test_data_size:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,acc in enumerate(test_correct):\n    print(f'Test accuracy for ephoch-{i+1}: {acc.item()*100/test_data_size:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manual evaluation on test set\nmodelCNN.eval()\ncorr_pred = 0\nact = []\npred = []\n\nfor img_batch, labs in test_loader:\n    for i,img in enumerate(img_batch):\n        with torch.no_grad():\n            new_pred = modelCNN(img.view(1,3,224,224).cuda()).argmax()\n        \n        #print(f'Predicted Class: {class_names[new_pred.item()]}  Actual Class: {class_names[labs[i].item()]}')\n        act.append(class_names[labs[i].item()])\n        pred.append(class_names[new_pred.item()])\n        \n        if class_names[new_pred.item()]==class_names[labs[i].item()]:\n            corr_pred+=1\nprint(f\"\\nCorrectly Predicted (CNN): {corr_pred} \")\nprint(f\"\\nTest Set Accuracy (CNN): {100*corr_pred/len(test_data):.2f}% \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(act,pred)\nplot_confusion_matrix(cm,normalize=False,target_names = class_names, title= \"Confusion Matrix for Custom CNN\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall = np.diag(cm) / np.sum(cm, axis = 1)\nprecision = np.diag(cm) / np.sum(cm, axis = 0)\n# print(f\"Recall (CNN): {recall}\")\n# print(f\"Precision (CNN): {precision}\")\nevalDict = {}\nevalDict['Class Name'] = class_names\nevalDict['Recall'] = recall\nevalDict['Precision'] = precision\nevalDf = pd.DataFrame(evalDict)\nevalDf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing a single image\nimg_index = 50\n#test data already transformed and normalized (denormalized to view them in plt.imshow)\nim_test = inverse_normalized(test_data[img_index][0]) \nplt.imshow(np.transpose(im_test.numpy(), (1,2,0)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating model with a single image from dataset\nmodelCNN.eval() \n\nwith torch.no_grad():\n    new_pred = modelCNN(test_data[img_index][0].view(1,3,224,224).cuda()).argmax()\n\nprint(f'Predicted class: {class_names[new_pred.item()]}')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-trained Models\n#### 1. **Alexnet**\n#### 2. **Resnet**\n#### 3. **VGG-16**\n#### 4. **ZFNET**\n#### 5. **GoogLeNet**","metadata":{}},{"cell_type":"markdown","source":"## 1. Alexnet","metadata":{}},{"cell_type":"code","source":"modelAlexnet = models.alexnet(pretrained=True)\n#Freezing pretrained parameters (w,b)\n\nfor param in modelAlexnet.parameters():\n    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparams\nALEXLR = 0.001\nALEXEPOCH = 4\nALEXSEED = 42\nALEXDROPOUT  = 0.5\nALEX_MAX_BATCH_SIZE = 99999999\ntorch.manual_seed(ALEXSEED)\ntorch.cuda.manual_seed(ALEXSEED)\n\n#Modifying the classicification section \nmodelAlexnet.classifier = nn.Sequential(nn.Linear(9216,1024),\n                                       nn.ReLU(),\n                                       nn.Dropout(ALEXDROPOUT),\n                                       nn.Linear(1024,512),\n                                       nn.ReLU(),\n                                       nn.Linear(512,256),\n                                       nn.ReLU(),\n                                       nn.Linear(256,3),\n                                       nn.LogSoftmax(dim=1))\n\nmodelAlexnet = modelAlexnet.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelAlexnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_params = 0\nfor parameters in modelAlexnet.parameters():\n    print(parameters.numel())\n    total_params += parameters.numel()\nprint(f\"Total params (alexnet): {total_params/1000000} mil\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(modelAlexnet.classifier.parameters(), lr=ALEXLR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelAlexnet.train()\nstart_time = time.time()\n\n#Limiting batch sizes\nmax_trn_batch = ALEX_MAX_BATCH_SIZE #600 \nmax_tst_batch = ALEX_MAX_BATCH_SIZE #200 \n\n# Tracking losses\ntrain_losses_anet = []\ntest_losses_anet = []\ntrain_correct_anet = []\ntest_correct_anet = []\n\n\nfor i in range(ALEXEPOCH):\n    trn_corr = 0\n    tst_corr = 0\n\n    for b, (X_train, y_train) in enumerate(train_loader):\n            \n          #Limiting batch sizes for testing the model\n        if b==max_trn_batch:\n            break\n\n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n        \n        b+=1\n        y_pred = modelAlexnet(X_train)\n        loss = criterion(y_pred, y_train) #Loss calculation\n\n        #Storing #correct predictions\n        predicted = torch.max(y_pred.data,1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n\n        #Backprop -> updating parameters\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (b%10 ==0):\n            print(f\"Epoch:{i+1} Batch:{b} Loss:{loss.item():.7f} accuracy:{trn_corr.item()*100/(10*b):7.3f}% \")\n      \n    train_losses_anet.append(loss)\n    train_correct_anet.append(trn_corr)\n\n    # For test Set\n    with torch.no_grad():\n        for b,(X_test,y_test) in enumerate(test_loader):\n            if( b==max_tst_batch):\n                break\n            \n            X_test = X_test.to(device)\n            y_test = y_test.to(device)\n            \n            y_test_pred = modelAlexnet(X_test)\n            predicted = torch.max(y_test_pred.data,1)[1]\n            batch_corr = (predicted == y_test).sum()\n            tst_corr = tst_corr + batch_corr\n\n    loss = criterion(y_test_pred, y_test)\n    test_losses_anet.append(loss)\n    test_correct_anet.append(tst_corr)\n\ntotal_time = time.time() - start_time\nprint(f'Time taken: {total_time/60} mins')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses_anet, label='training loss')\nplt.plot(test_losses_anet, label='validation loss')\nplt.title('Train-Test Loss')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([t/270 for t in train_correct_anet], label='training accuracy')\nplt.plot([t/30 for t in test_correct_anet], label='validation accuracy')\nplt.title('Accuracy at the end of each epoch (ALEXNET)')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_correct_anet)\ntest_data_size = len(test_data)\nprint(f'Test accuracy: {test_correct_anet[-1].item()*100/test_data_size:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,acc in enumerate(test_correct_anet):\n    print(f'Test accuracy for ephoch-{i+1}: {acc.item()*100/test_data_size:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing a single image\nimg_index = 73\n#test data already transformed and normalized (denormalized to view them in plt.imshow)\nim_test = inverse_normalized(test_data[img_index][0]) \nplt.imshow(np.transpose(im_test.numpy(), (1,2,0)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating model with a single image from dataset\nmodelAlexnet.eval() \n\nwith torch.no_grad():\n    new_pred = modelAlexnet(test_data[img_index][0].view(1,3,224,224).cuda()).argmax()\n\nprint(f'Predicted class: {class_names[new_pred.item()]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manual evaluation on test set\nmodelAlexnet.eval()\ncorr_pred = 0\nact = []\npred = []\n\nfor img_batch, labs in test_loader:\n    for i,img in enumerate(img_batch):\n        with torch.no_grad():\n            new_pred = modelAlexnet(img.view(1,3,224,224).cuda()).argmax()\n        \n        #print(f'Predicted Class: {class_names[new_pred.item()]}  Actual Class: {class_names[labs[i].item()]}')\n        act.append(class_names[labs[i].item()])\n        pred.append(class_names[new_pred.item()])\n        \n        if class_names[new_pred.item()]==class_names[labs[i].item()]:\n            corr_pred+=1\nprint(f\"\\nCorrectly Predicted (ALEXNET): {corr_pred} \")\nprint(f\"\\nTest Set Accuracy (ALEXNET): {100*corr_pred/len(test_data):.2f}% \")\n\n#Print as dataframe\n# evalDict = {}\n# evalDict['Actual'] = act\n# evalDict['Predicted'] = pred\n# evalDf = pd.DataFrame(evalDict)\n# #evalDf.head(300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(act,pred)\nplot_confusion_matrix(cm,normalize=False,target_names = class_names, title= \"Confusion Matrix for ALEXNET\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall = np.diag(cm) / np.sum(cm, axis = 1)\nprecision = np.diag(cm) / np.sum(cm, axis = 0)\nevalDict = {}\nevalDict['Class Name'] = class_names\nevalDict['Recall'] = recall\nevalDict['Precision'] = precision\nevalDf = pd.DataFrame(evalDict)\nevalDf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Resnet\n","metadata":{}},{"cell_type":"code","source":"modelResnet = models.resnet18(pretrained=True)\n\nfor param in modelResnet.parameters():\n    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"default_infeatures = modelResnet.fc.in_features\nmodelResnet.fc = nn.Linear(default_infeatures, len(class_names))\nmodelResnet.fc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_params = 0\nfor parameters in modelResnet.parameters():\n  #print(parameters.numel())\n  total_params += parameters.numel()\nprint(f\"Total params (alexnet): {total_params/1000000} mil\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelResnet = modelResnet.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyper parameters\nresLR = 0.001\nresMomentum = 0.9\nresStepSize = 5\nresGamma = 0.1\nresEPOCH = 9\nRESSEED = 101\n\ntorch.manual_seed(RESSEED)\ntorch.cuda.manual_seed(RESSEED)\n\ncriterion = nn.CrossEntropyLoss()\n#SGD as optimizer with lr and momentum\noptimizer = torch.optim.SGD(modelResnet.fc.parameters(), lr= resLR, momentum= resMomentum)\n# Exponential learning rate\nexp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = resStepSize, gamma = resGamma)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelResnet.train()\n\nstart_time = time.time()\n\n# Tracking losses\ntrain_losses_resnet = []\ntest_losses_resnet = []\ntrain_correct_resnet = []\ntest_correct_resnet = []\n\n\nfor i in range(resEPOCH):\n    trn_corr = 0\n    tst_corr = 0\n\n    for b, (X_train, y_train) in enumerate(train_loader):\n            \n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n        \n        b+=1\n        y_pred = modelResnet(X_train)\n        loss = criterion(y_pred, y_train) #Loss calculation\n\n        #Storing #correct predictions\n        predicted = torch.max(y_pred.data,1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n\n        #Backprop -> updating parameters\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (b%70 ==0):\n            print(f\"Epoch:{i+1} Batch:{b} Loss:{loss.item():.7f} accuracy:{trn_corr.item()*100/(10*b):7.3f}% \")\n    \n    exp_lr_scheduler.step() \n    train_losses_resnet.append(loss)\n    train_correct_resnet.append(trn_corr)\n\n    # For test Set\n    with torch.no_grad():\n        for b,(X_test,y_test) in enumerate(test_loader):\n            \n            X_test = X_test.to(device)\n            y_test = y_test.to(device)\n            \n            y_test_pred = modelResnet(X_test)\n            predicted = torch.max(y_test_pred.data,1)[1]\n            batch_corr = (predicted == y_test).sum()\n            tst_corr = tst_corr + batch_corr\n\n    loss = criterion(y_test_pred, y_test)\n    test_losses_resnet.append(loss)\n    test_correct_resnet.append(tst_corr)\n\ntotal_time = time.time() - start_time\nprint(f'Time taken: {total_time/60} mins')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses_resnet, label='training loss')\nplt.plot(test_losses_resnet, label='validation loss')\nplt.title('Train-Test Loss')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-09-14T13:54:20.562788Z","iopub.execute_input":"2021-09-14T13:54:20.563249Z","iopub.status.idle":"2021-09-14T13:54:20.834333Z","shell.execute_reply.started":"2021-09-14T13:54:20.563218Z","shell.execute_reply":"2021-09-14T13:54:20.832741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([t/270 for t in train_correct_resnet], label='training accuracy')\nplt.plot([t/30 for t in test_correct_resnet], label='validation accuracy')\nplt.title('Accuracy at the end of each epoch (RESNET)')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-09-14T13:54:25.716481Z","iopub.execute_input":"2021-09-14T13:54:25.716857Z","iopub.status.idle":"2021-09-14T13:54:25.953999Z","shell.execute_reply.started":"2021-09-14T13:54:25.716825Z","shell.execute_reply":"2021-09-14T13:54:25.952546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_correct_resnet)\ntest_data_size = len(test_data)\nprint(f'\\nTest accuracy (max): {np.array(test_correct_resnet).max().item()*100/test_data_size:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T13:54:29.220108Z","iopub.execute_input":"2021-09-14T13:54:29.220501Z","iopub.status.idle":"2021-09-14T13:54:29.231942Z","shell.execute_reply.started":"2021-09-14T13:54:29.220467Z","shell.execute_reply":"2021-09-14T13:54:29.23033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accuracy for each epoch\nfor i,acc in enumerate(test_correct_resnet):\n    print(f'Test accuracy for ephoch-{i+1}: {acc.item()*100/test_data_size:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manual evaluation on test set\nmodelResnet.eval()\ncorr_pred = 0\nact = []\npred = []\nfor img_batch, labs in test_loader:\n    for i,img in enumerate(img_batch):\n        with torch.no_grad():\n            new_pred = modelResnet(img.view(1,3,224,224).cuda()).argmax()\n        \n        #print(f'Predicted Class: {class_names[new_pred.item()]}  Actual Class: {class_names[labs[i].item()]}')\n        act.append(labs[i].item())\n        pred.append(new_pred.item())\n        \n        if class_names[new_pred.item()]==class_names[labs[i].item()]:\n            corr_pred+=1\nprint(f\"\\nCorrectly Predicted (Resnet): {corr_pred} \")\nprint(f\"\\nTest Set Accuracy (Resnet): {100*corr_pred/len(test_data):.2f}% \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(act,pred)\nplot_confusion_matrix(cm,normalize=False,target_names = class_names, title= \"Confusion Matrix for RESNET\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall = np.diag(cm) / np.sum(cm, axis = 1)\nprecision = np.diag(cm) / np.sum(cm, axis = 0)\nevalDict = {}\nevalDict['Class Name'] = class_names\nevalDict['Recall'] = recall\nevalDict['Precision'] = precision\nevalDf = pd.DataFrame(evalDict)\nevalDf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving a trained model\n\ntorch.save(modelResnet.state_dict(), '/a')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T13:56:23.635356Z","iopub.execute_input":"2021-09-14T13:56:23.635781Z","iopub.status.idle":"2021-09-14T13:56:23.790776Z","shell.execute_reply.started":"2021-09-14T13:56:23.635748Z","shell.execute_reply":"2021-09-14T13:56:23.789527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pwdccd\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T13:56:26.029193Z","iopub.execute_input":"2021-09-14T13:56:26.02964Z","iopub.status.idle":"2021-09-14T13:56:26.039169Z","shell.execute_reply.started":"2021-09-14T13:56:26.029608Z","shell.execute_reply":"2021-09-14T13:56:26.037728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. VGG-16","metadata":{}},{"cell_type":"code","source":"modelVGG = models.vgg16(pretrained=True)\nfor param in modelVGG.parameters():\n    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparams\nVGGLR = 0.001\nVGGEPOCH = 10\nVGGSEED = 42\nVGGDROPOUT  = 0.5\ntorch.manual_seed(VGGSEED)\ntorch.cuda.manual_seed(VGGSEED)\n\n\n#Modifying the classicification section \nmodelVGG.classifier = nn.Sequential(nn.Linear(25088,4096),\n                                    nn.ReLU(),\n                                    nn.Dropout(VGGDROPOUT),\n                                    nn.Linear(4096,1024),\n                                    nn.ReLU(),\n                                    nn.Dropout(VGGDROPOUT),\n                                    nn.Linear(1024,512),\n                                    nn.ReLU(),\n                                    nn.Dropout(VGGDROPOUT),\n                                    nn.Linear(512,256),\n                                    nn.ReLU(),\n                                    nn.Dropout(VGGDROPOUT),\n                                    nn.Linear(256,64),\n                                    nn.ReLU(),\n                                    nn.Dropout(VGGDROPOUT),\n                                    nn.Linear(64,3))\nmodelVGG = modelVGG.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_params = 0\nfor parameters in modelVGG.parameters():\n      total_params += parameters.numel()\nprint(f\"Total params (vgg16): {total_params/1000000} mil\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(modelVGG.classifier.parameters(), lr=VGGLR,momentum=0.9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelVGG.train()\nstart_time = time.time()\n\n# Tracking losses\ntrain_losses_vgg = []\ntest_losses_vgg = []\ntrain_correct_vgg = []\ntest_correct_vgg = []\n\n\nfor i in range(VGGEPOCH):\n    trn_corr = 0\n    tst_corr = 0\n\n    for b, (X_train, y_train) in enumerate(train_loader):\n\n\n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n        \n        b+=1\n        y_pred = modelVGG(X_train)\n        loss = criterion(y_pred, y_train) #Loss calculation\n\n        #Storing #correct predictions\n        predicted = torch.max(y_pred.data,1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n\n        #Backprop -> updating parameters\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (b%70 ==0):\n            print(f\"Epoch:{i+1} Batch:{b} Loss:{loss.item():.7f} accuracy:{trn_corr.item()*100/(10*b):7.3f}% \")\n      \n    train_losses_vgg.append(loss)\n    train_correct_vgg.append(trn_corr)\n\n    # For test Set\n    with torch.no_grad():\n        for b,(X_test,y_test) in enumerate(test_loader):\n            \n            X_test = X_test.to(device)\n            y_test = y_test.to(device)\n            \n            y_test_pred = modelVGG(X_test)\n            predicted = torch.max(y_test_pred.data,1)[1]\n            batch_corr = (predicted == y_test).sum()\n            tst_corr = tst_corr + batch_corr\n\n    loss = criterion(y_test_pred, y_test)\n    test_losses_vgg.append(loss)\n    test_correct_vgg.append(tst_corr)\n\ntotal_time = time.time() - start_time\nprint(f'Time taken: {total_time/60} mins')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses_vgg, label='training loss')\nplt.plot(test_losses_vgg, label='validation loss')\nplt.title('Train-Test Loss')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([t/270 for t in train_correct_vgg], label='training accuracy')\nplt.plot([t/30 for t in test_correct_vgg], label='validation accuracy')\nplt.title('Accuracy at the end of each epoch (VGG16)')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,acc in enumerate(test_correct_vgg):\n    print(f'Test accuracy for ephoch-{i+1}: {acc.item()*100/len(test_data):.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manual evaluation on test set\nmodelVGG.eval()\ncorr_pred = 0\nact = []\npred = []\n\nfor img_batch, labs in test_loader:\n    for i,img in enumerate(img_batch):\n        with torch.no_grad():\n            new_pred = modelVGG(img.view(1,3,224,224).cuda()).argmax()\n        \n        #print(f'Predicted Class: {class_names[new_pred.item()]}  Actual Class: {class_names[labs[i].item()]}')\n        act.append(class_names[labs[i].item()])\n        pred.append(class_names[new_pred.item()])\n        \n        if class_names[new_pred.item()]==class_names[labs[i].item()]:\n            corr_pred+=1\nprint(f\"\\nCorrectly Predicted (VGG16): {corr_pred} \")\nprint(f\"\\nTest Set Accuracy (VGG16): {100*corr_pred/len(test_data):.2f}% \")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(act,pred)\nplot_confusion_matrix(cm,normalize=False,target_names = class_names, title= \"Confusion Matrix for VGG16\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall = np.diag(cm) / np.sum(cm, axis = 1)\nprecision = np.diag(cm) / np.sum(cm, axis = 0)\nevalDict = {}\nevalDict['Class Name'] = class_names\nevalDict['Recall'] = recall\nevalDict['Precision'] = precision\nevalDf = pd.DataFrame(evalDict)\nevalDf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. ZFNET","metadata":{}},{"cell_type":"code","source":"# ZFNet model\n#credit: Visualizing and Understanding Convolutional Networks\n#Source: https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf (/arvention/ZFNet-PyTorch)\n\nclass ZFNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 96, kernel_size=7, stride=2, padding=3, padding_mode='reflect') \n        self.conv2 = nn.Conv2d(96, 256, kernel_size=5, stride=2, padding=2, padding_mode='reflect')\n        self.conv3 = nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n        self.conv4 = nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n        self.conv5 = nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n        self.fc6 = nn.Linear(9216,4096)\n        self.fc7 = nn.Linear(4096,4096)\n        self.fc8 = nn.Linear(4096,3)\n        self.pool1 = nn.MaxPool2d(3,stride=2)\n        self.pool2 = nn.MaxPool2d(3,stride=2)\n        self.drop = nn.Dropout(0.5)\n        self.drop = nn.Dropout(0.5)\n        self.lrn = nn.LocalResponseNorm(size=5,alpha=10e-4,beta=0.75,k=2.0)\n\n    def forward(self, x):\n        x = self.lrn(self.pool1(F.relu(self.conv1(x))))\n        x = self.lrn(self.pool2(F.relu(self.conv2(x))))\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = self.pool2(F.relu(self.conv5(x)))\n        x = x.view(-1,9216)\n        x = F.relu(self.drop(self.fc6(x)))\n        x = F.relu(self.drop(self.fc7(x)))\n        x = self.fc8(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelZfnet = ZFNet()\nmodelZfnet = modelZfnet.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_params = 0\nfor parameters in modelZfnet.parameters():\n      total_params += parameters.numel()\nprint(f\"Total params (ZFNet): {total_params/1000000} mil\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparams\nZFLR = 0.001\nZFEPOCH = 15\nZFSEED = 42\ntorch.manual_seed(ZFSEED)\ntorch.cuda.manual_seed(ZFSEED)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(modelZfnet.parameters(), lr=ZFLR,momentum=0.9)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelZfnet.train()\nstart_time = time.time()\n\n# Tracking losses\ntrain_losses_zf = []\ntest_losses_zf = []\ntrain_correct_zf = []\ntest_correct_zf = []\n\n\nfor i in range(ZFEPOCH):\n    trn_corr = 0\n    tst_corr = 0\n\n    for b, (X_train, y_train) in enumerate(train_loader):\n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n        b+=1\n        y_pred = modelZfnet(X_train)\n        loss = criterion(y_pred, y_train) #Loss calculation\n\n        #Storing #correct predictions\n        predicted = torch.max(y_pred.data,1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n\n        #Backprop -> updating parameters\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (b%70 ==0):\n            print(f\"Epoch:{i+1} Batch:{b} Loss:{loss.item():.7f} accuracy:{trn_corr.item()*100/(10*b):7.3f}% \")\n      \n    train_losses_zf.append(loss)\n    train_correct_zf.append(trn_corr)\n\n    # For test Set\n    with torch.no_grad():\n        for b,(X_test,y_test) in enumerate(test_loader):\n            \n            X_test = X_test.to(device)\n            y_test = y_test.to(device)\n            \n            y_test_pred = modelZfnet(X_test)\n            predicted = torch.max(y_test_pred.data,1)[1]\n            batch_corr = (predicted == y_test).sum()\n            tst_corr = tst_corr + batch_corr\n\n    loss = criterion(y_test_pred, y_test)\n    test_losses_zf.append(loss)\n    test_correct_zf.append(tst_corr)\n\ntotal_time = time.time() - start_time\nprint(f'Time taken: {total_time/60} mins')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses_zf, label='training loss')\nplt.plot(test_losses_zf, label='validation loss')\nplt.title('Train-Test Loss')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([t/270 for t in train_correct_zf], label='training accuracy')\nplt.plot([t/30 for t in test_correct_zf], label='validation accuracy')\nplt.title('Accuracy at the end of each epoch (ZFNet)')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,acc in enumerate(test_correct_zf):\n    print(f'Test accuracy for ephoch-{i+1}: {acc.item()*100/len(test_data):.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manual evaluation on test set\nmodelZfnet.eval()\ncorr_pred = 0\nact = []\npred = []\n\nfor img_batch, labs in test_loader:\n    for i,img in enumerate(img_batch):\n        with torch.no_grad():\n            new_pred = modelZfnet(img.view(1,3,224,224).cuda()).argmax()\n        \n        #print(f'Predicted Class: {class_names[new_pred.item()]}  Actual Class: {class_names[labs[i].item()]}')\n        act.append(class_names[labs[i].item()])\n        pred.append(class_names[new_pred.item()])\n        \n        if class_names[new_pred.item()]==class_names[labs[i].item()]:\n            corr_pred+=1\nprint(f\"\\nCorrectly Predicted (ZFNET): {corr_pred} \")\nprint(f\"\\nTest Set Accuracy (ZFNET): {100*corr_pred/len(test_data):.2f}% \")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(act,pred)\nplot_confusion_matrix(cm,normalize=False,target_names = class_names, title= \"Confusion Matrix for ZFNET\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall = np.diag(cm) / np.sum(cm, axis = 1)\nprecision = np.diag(cm) / np.sum(cm, axis = 0)\nevalDict = {}\nevalDict['Class Name'] = class_names\nevalDict['Recall'] = recall\nevalDict['Precision'] = precision\nevalDf = pd.DataFrame(evalDict)\nevalDf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. GoogLeNet","metadata":{}},{"cell_type":"code","source":"modelGNET = models.googlenet(pretrained=True)\nfor param in modelGNET.parameters():\n    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_params = 0\nfor parameters in modelGNET.parameters():\n      total_params += parameters.numel()\nprint(f\"Total params (GoogLeNet): {total_params/1000000} mil\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Modifying the FC layer\nmodelGNET.fc = nn.Linear(modelGNET.fc.in_features, len(class_names))\nmodelGNET = modelGNET.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyper parameters\nGNLR = 0.001\nGNMomentum = 0.9\nGNEPOCH = 15\nGNSEED = 101\n\ntorch.manual_seed(GNSEED)\ntorch.cuda.manual_seed(GNSEED)\n\ncriterion = nn.CrossEntropyLoss()\n#SGD as optimizer with lr and momentum\noptimizer = torch.optim.SGD(modelGNET.fc.parameters(), lr= GNLR, momentum= GNMomentum)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelGNET.train()\n\nstart_time = time.time()\n\n# Tracking losses\ntrain_losses_gn = []\ntest_losses_gn = []\ntrain_correct_gn = []\ntest_correct_gn = []\n\n\nfor i in range(GNEPOCH):\n    trn_corr = 0\n    tst_corr = 0\n\n    for b, (X_train, y_train) in enumerate(train_loader):\n            \n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n        \n        b+=1\n        y_pred = modelGNET(X_train)\n        loss = criterion(y_pred, y_train) #Loss calculation\n\n        #Storing #correct predictions\n        predicted = torch.max(y_pred.data,1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n\n        #Backprop -> updating parameters\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (b%70 ==0):\n            print(f\"Epoch:{i+1} Batch:{b} Loss:{loss.item():.7f} accuracy:{trn_corr.item()*100/(10*b):7.3f}% \")\n    \n    train_losses_gn.append(loss)\n    train_correct_gn.append(trn_corr)\n\n    # For test Set\n    with torch.no_grad():\n        for b,(X_test,y_test) in enumerate(test_loader):\n            \n            X_test = X_test.to(device)\n            y_test = y_test.to(device)\n            \n            y_test_pred = modelGNET(X_test)\n            predicted = torch.max(y_test_pred.data,1)[1]\n            batch_corr = (predicted == y_test).sum()\n            tst_corr = tst_corr + batch_corr\n\n    loss = criterion(y_test_pred, y_test)\n    test_losses_gn.append(loss)\n    test_correct_gn.append(tst_corr)\n\ntotal_time = time.time() - start_time\nprint(f'Time taken: {total_time/60} mins')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses_gn, label='training loss')\nplt.plot(test_losses_gn, label='validation loss')\nplt.title('Train-Test Loss')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([t/270 for t in train_correct_gn], label='training accuracy')\nplt.plot([t/30 for t in test_correct_gn], label='validation accuracy')\nplt.title('Accuracy at the end of each epoch (GoogLeNet)')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_correct_gn)\ntest_data_size = len(test_data)\nprint(f'\\nTest accuracy (max): {np.array(test_correct_gn).max().item()*100/test_data_size:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accuracy for each epoch\nfor i,acc in enumerate(test_correct_gn):\n    print(f'Test accuracy for ephoch-{i+1}: {acc.item()*100/test_data_size:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manual evaluation on test set\nmodelGNET.eval()\ncorr_pred = 0\nact = []\npred = []\nfor img_batch, labs in test_loader:\n    for i,img in enumerate(img_batch):\n        with torch.no_grad():\n            new_pred = modelGNET(img.view(1,3,224,224).cuda()).argmax()\n        \n        #print(f'Predicted Class: {class_names[new_pred.item()]}  Actual Class: {class_names[labs[i].item()]}')\n        act.append(labs[i].item())\n        pred.append(new_pred.item())\n        \n        if class_names[new_pred.item()]==class_names[labs[i].item()]:\n            corr_pred+=1\nprint(f\"\\nCorrectly Predicted (GoogLeNet): {corr_pred} \")\nprint(f\"\\nTest Set Accuracy (GoogLeNet): {100*corr_pred/len(test_data):.2f}% \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(act,pred)\nplot_confusion_matrix(cm,normalize=False,target_names = class_names, title= \"Confusion Matrix for GoogLeNet\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall = np.diag(cm) / np.sum(cm, axis = 1)\nprecision = np.diag(cm) / np.sum(cm, axis = 0)\nevalDict = {}\nevalDict['Class Name'] = class_names\nevalDict['Recall'] = recall\nevalDict['Precision'] = precision\nevalDf = pd.DataFrame(evalDict)\nevalDf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MobileNet V2","metadata":{}},{"cell_type":"code","source":"modelMNet = models.mobilenet_v2(pretrained=True)\nfor param in modelMNet.parameters():\n    param.requires_grad = False\n    \nmodelMNet.classifier[1] = nn.Linear(1280,3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyper parameters\nSEED = 101\nLEARNING_RATE = 0.001\nEPOCHS = 40\nMAX_BATCH_SIZE = 9999999 #unlimited (whole dataset)\n\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\n\n\nmodelMNet = modelMNet.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(modelMNet.classifier.parameters(), lr= LEARNING_RATE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.watch(modelMNet)\n\nmodelMNet.train()\nstart_time = time.time()\n\n# Tracking losses\ntrain_losses_mnet = []\ntest_losses_mnet = []\ntrain_correct_mnet = []\ntest_correct_mnet = []\n\n\nfor i in range(EPOCHS):\n    trn_corr = 0\n    tst_corr = 0\n\n    for b, (X_train, y_train) in enumerate(train_loader):\n            \n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n        \n        b+=1\n        y_pred = modelMNet(X_train)\n        loss = criterion(y_pred, y_train) #Loss calculation\n\n        #Storing #correct predictions\n        predicted = torch.max(y_pred.data,1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n\n        #Backprop -> updating parameters\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (b%270 ==0):\n            #wandb.log({\"Loss\":loss.item()})\n            #wandb.log({\"Accuracy(Train)%\":trn_corr.item()*100/(10*b)})\n            print(f\"Epoch:{i+1} Batch:{b} Loss:{loss.item():.7f} accuracy:{trn_corr.item()*100/(10*b):7.3f}% \")\n      \n    train_losses_mnet.append(loss)\n    train_correct_mnet.append(trn_corr)\n\n    # For test Set\n    with torch.no_grad():\n        for b,(X_test,y_test) in enumerate(test_loader):\n            \n            X_test = X_test.to(device)\n            y_test = y_test.to(device)\n            \n            y_test_pred = modelMNet(X_test)\n            predicted = torch.max(y_test_pred.data,1)[1]\n            batch_corr = (predicted == y_test).sum()\n            tst_corr = tst_corr + batch_corr\n        wandb.log({\"Accuracy(Test)%\":100*tst_corr.item()/300,\"Epochs\": i})\n\n    loss = criterion(y_test_pred, y_test)\n    test_losses_mnet.append(loss)\n    test_correct_mnet.append(tst_corr)\n\ntotal_time = time.time() - start_time\nprint(f'Time taken: {total_time/60} mins')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelMNet.eval()\ncorr_pred = 0\nact = []\npred = []\n\nfor img_batch, labs in test_loader:\n    for i,img in enumerate(img_batch):\n        with torch.no_grad():\n            new_pred = modelMNet(img.view(1,3,224,224).cuda()).argmax()\n            \n        #print(f'Predicted Class: {class_names[new_pred.item()]}  Actual Class: {class_names[labs[i].item()]}')\n        act.append(class_names[labs[i].item()])\n        pred.append(class_names[new_pred.item()])\n        \n        if class_names[new_pred.item()]==class_names[labs[i].item()]:\n            corr_pred+=1\n\nprint(f\"\\nCorrectly Predicted (MNET): {corr_pred} \")\nprint(f\"\\nTest Set Accuracy (MNET): {100*corr_pred/len(test_data):.2f}% \")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Some Leftover Evaluation","metadata":{}},{"cell_type":"code","source":"data = {'C-CNN':83.67, 'ALEXNET':90.67, 'RESNET':93.67,\n        'VGG16':93.33 ,'ZFNET':86, 'GOOGLENET': 91.33, 'MobileNet' : 92.33}\ncourses = list(data.keys())\nvalues = list(data.values())\nfig = plt.figure(figsize = (10, 5))\nplt.bar(courses, values, color ='orange',width = 0.4)\nplt.xlabel(\"Architectures\")\nplt.ylabel(\"Test Accuracy\")\nplt.title(\"Test Accuracy of Different Approaches\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}